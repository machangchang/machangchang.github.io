---
layout: post
title: 时间复杂度
categories: 算法
description: 算法
keywords: 时间复杂度
---

# 时间复杂度

在大学里学的时间复杂度的相关知识基本上都还给老师了，所以在这里复习一下。

## 1. 时间频度

一个算法执行所耗费的时间，从理论上是不能算出来的，必须上机运行测试才能知道。但我们不可能也没有必要对每个算法都上机测试，只需知道哪个算法花费的时间多，哪个算法花费的时间少就可以了。并且一个算法花费的时间与算法中语句的执行次数成正比例，哪个算法中语句执行次数多，它花费时间就多。一个算法中的语句执行次数称为语句频度或时间频度。记为T(n)。

## 2. 时间复杂度

前面提到的时间频度T(n)中，n称为问题的规模，当n不断变化时，时间频度T(n)也会不断变化。但有时我们想知道它变化时呈现什么规律，为此我们引入时间复杂度的概念。一般情况下，算法中基本操作重复执行的次数是问题规模n的某个函数，用T(n)表示，若有某个辅助函数f(n)，使得当n趋近于无穷大时，T（n)/f(n)的极限值为不等于零的常数，则称f(n)是T(n)的同数量级函数，记作T(n)=O(f(n))，它称为算法的渐进时间复杂度，简称时间复杂度。

## 3. 大O表示法

像前面用O( )来体现算法时间复杂度的记法，我们称之为大O表示法。

算法复杂度可以从最理想情况、平均情况和最坏情况三个角度来评估，由于平均情况大多和最坏情况持平，而且评估最坏情况也可以避免后顾之忧，因此一般情况下，我们设计算法时都要直接估算最坏情况的复杂度。

大O表示法O(f(n)中的f(n)的值可以为1、n、logn、n²等，因此我们可以将O(1)、O(n)、O(logn)、O(n²)分别可以称为常数阶、线性阶、对数阶和平方阶，那么如何推导出f(n)的值呢？我们接着来看推导大O阶的方法。

### 3.1 推导大O阶

推导大O阶，我们可以按照如下的规则来进行推导，得到的结果就是大O表示法：

1. 用常数1来取代运行时间中所有加法常数。

2. 修改后的运行次数函数中，只保留最高阶项

3. 如果最高阶项存在且不是1，则去除与这个项相乘的常数。

### 3.2 常数阶

如下所示：

```java
int sum = 0,n = 100; //执行一次  
sum = (1+n)*n/2; //执行一次  
System.out.println (sum); //执行一次
```

上面算法的运行的次数的函数为f(n)=3，根据推导大O阶的规则1，我们需要将常数3改为1，则这个算法的时间复杂度为O(1)。如果sum = （1+n）*n/2这条语句再执行10遍，因为这与问题大小n的值并没有关系，所以这个算法的时间复杂度仍旧是O(1)，我们可以称之为常数阶。

### 3.3 线性阶

线性阶主要要分析循环结构的运行情况，如下所示：

```java
for(int i=0;i<n;i++){
//时间复杂度为O(1)的算法
...
}
```

上面算法循环体中的代码执行了n次，因此时间复杂度为O(n)。

### 3.4 对数阶

如下所示：

```java
int number=1;
while(number<n){
number=number*2;
//时间复杂度为O(1)的算法
...
}
```

可以看出上面的代码，随着number每次乘以2后，都会越来越接近n，当number不小于n时就会退出循环。假设循环的次数为X，则由2^x=n得出x=log₂n，因此得出这个算法的时间复杂度为O(logn)。

其中关于算法的时间复杂度很多都用包含O(logN)这样的描述，但是却没有明确说logN的底数究竟是多少。这里解释下。

算法中log级别的时间复杂度都是由于使用了分治思想,这个底数直接由分治的复杂度决定。

如果采用二分法,那么就会以2为底数,三分法就会以3为底数,其他亦然。

不过无论底数是什么,log级别的渐进意义是一样的。

也就是说该算法的时间复杂度的增长与处理数据多少的增长的关系是一样的。

我们先考虑O(logx(n))和O(logy(n))，x!=y，我们是在考虑n趋于无穷的情况。

求当n趋于无穷大时logx(n)/logy(n)的极限可以发现，极限等于lny/lnx，也就是一个常数，

也就是说，在n趋于无穷大的时候，这两个东西仅差一个常数。

所以从研究算法的角度log的底数不重要。

### 3.5 平方阶

下面的代码是循环嵌套：

```java
for(int i=0;i<n;i++){   
      for(int j=0;j<n;i++){
         //复杂度为O(1)的算法
         ... 
    }
}
```

内层循环的时间复杂度在讲到线性阶时就已经得知是O(n)，现在经过外层循环n次，那么这段算法的时间复杂度则为O(n²)。

接下来我们来算一下下面算法的时间复杂度：

```java
 for(int i=0;i<n;i++){   
      for(int j=i;j<n;i++){
         //复杂度为O(1)的算法
         ... 
      }
 }
```

需要注意的是内循环中int j=i，而不是int j=0。当i=0时，内循环执行了n次；i=1时内循环执行了n-1次，当i=n-1时执行了1次，我们可以推算出总的执行次数为：

```java
n+(n-1)+(n-2)+(n-3)+……+1
=(n+1)+[(n-1)+2]+[(n-2)+3]+[(n-3)+4]+……
=(n+1)+(n+1)+(n+1)+(n+1)+……
=(n+1)n/2
=n(n+1)/2
=n²/2+n/2
```

根据此前讲过的推导大O阶的规则的第二条：只保留最高阶，因此保留n²/2。根据第三条去掉和这个项的常数，则去掉1/2,最终这段代码的时间复杂度为O(n²)。

> 转载链接：https://juejin.im/post/58d15f1044d90400691834d4
> https://blog.csdn.net/jdbc/article/details/42173751
