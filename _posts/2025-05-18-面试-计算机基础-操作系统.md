---
layout: post
title: 面试-计算机基础-操作系统
categories: 面试
description: 操作系统
keywords: 操作系统
---

### 什么是操作系统？
可以这么说，操作系统是一种运行在内核态的软件。
它是应用程序和硬件之间的媒介，向应用程序提供硬件的抽象，以及管理硬件资源。
![image](https://github.com/user-attachments/assets/a0d7057e-f501-4d7f-8cc7-55cb46439dec)

### 操作系统主要有哪些功能？
操作系统最主要的功能：
处理器（CPU）管理：CPU的管理和分配，主要指的是进程管理。
内存管理：内存的分配和管理，主要利用了虚拟内存的方式。
外存管理：外存（磁盘等）的分配和管理，将外存以文件的形式提供出去。
I/O管理：对输入/输出设备的统一管理。
除此之外，还有保证自身正常运行的健壮性管理，防止非法操作和入侵的安全性管理。
![image](https://github.com/user-attachments/assets/fcfe6b30-27e8-41c1-bd1f-6b96d96fe820)

### 什么是用户态和内核态？
内核具有很⾼的权限，可以控制 cpu、内存、硬盘等硬件，出于权限控制的考虑，因此⼤多数操作系统，把内存分成了两个区域：
内核空间，这个内存空间只有内核程序可以访问；
⽤户空间，这个内存空间专⻔给应⽤程序使⽤，权限比较小；
⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。因此，当程序使⽤⽤户空间时，我们常说该程序在⽤户态执⾏，⽽当程序使内核空间时，程序则在内核态执⾏。

### 用户态和内核态是如何切换的？
应⽤程序如果需要进⼊内核空间，就需要通过系统调⽤，来进入内核态：
![image](https://github.com/user-attachments/assets/498264a1-f177-40ec-b4b1-3f3212a27dd6)
内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作。

### 并行和并发有什么区别？
并发就是在一段时间内，多个任务都会被处理；但在某一时刻，只有一个任务在执行。单核处理器做到的并发，其实是利用时间片的轮转，例如有两个进程A和B，A运行一个时间片之后，切换到B，B运行一个时间片之后又切换到A。因为切换速度足够快，所以宏观上表现为在一段时间内能同时运行多个程序。
并行就是在同一时刻，有多个任务在执行。这个需要多核处理器才能完成，在微观上就能同时执行多条指令，不同的程序被放到不同的处理器上运行，这个是物理上的多个进程同时进行。
![image](https://github.com/user-attachments/assets/7914e9c0-fe47-4d0b-bd85-6479c2661660)

### 什么是进程上下文切换？
对于单核单线程 CPU 而言，在某一时刻只能执行一条 CPU 指令。上下文切换 (Context Switch) 是一种将 CPU 资源从一个进程分配给另一个进程的机制。从用户角度看，计算机能够并行运行多个进程，这恰恰是操作系统通过快速上下文切换造成的结果。在切换的过程中，操作系统需要先存储当前进程的状态 (包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。
![image](https://github.com/user-attachments/assets/7bc1a6d0-066e-40ae-975a-b976af7c4742)

### 进程有哪些状态？
当一个进程开始运行时，它可能会经历下面这几种状态：
运⾏状态（Runing）：该时刻进程占⽤ CPU；
就绪状态（Ready）：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏；
阻塞状态（Blocked）：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时，即使给它CPU控制权，它也⽆法运⾏；
![image](https://github.com/user-attachments/assets/8547bccc-0b9c-489c-ab05-361424f68465)
当然，进程还有另外两个基本状态：
创建状态（new）：进程正在被创建时的状态；
结束状态（Exit）：进程正在从系统中消失时的状态；
![image](https://github.com/user-attachments/assets/a17fe925-3b7c-41d1-ac20-09e216a5692e)

### 什么是僵尸进程？
僵尸进程是已完成且处于终止状态，但在进程表中却仍然存在的进程。
僵尸进程一般发生有父子关系的进程中，一个子进程的进程描述符在子进程退出时不会释放，只有当父进程通过 wait() 或 waitpid() 获取了子进程信息后才会释放。如果子进程退出，而父进程并没有调用 wait() 或 waitpid()，那么子进程的进程描述符仍然保存在系统中。

### 什么是孤儿进程？
一个父进程退出，而它的一个或多个子进程还在运行，那么这些子进程将成为孤儿进程。孤儿进程将被 init 进程 (进程 ID 为 1 的进程) 所收养，并由 init 进程对它们完成状态收集工作。因为孤儿进程会被 init 进程收养，所以孤儿进程不会对系统造成危害。

### 进程有哪些调度算法？
进程调度就是确定某一个时刻CPU运行哪个进程，常见的进程调度算法有：
![image](https://github.com/user-attachments/assets/223e4288-9800-407f-8556-7f92f348f685)

先来先服务：
非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对I/O密集型进程也不利，因为这种进程每次进行I/O操作之后又得重新排队。
![image](https://github.com/user-attachments/assets/6fa99d94-d2e2-45bc-8748-a5a27a02334e)

短作业优先：
非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。
![image](https://github.com/user-attachments/assets/0508a7d1-11b6-4a5c-9bfd-8e12da006818)

优先级调度：
为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
![image](https://github.com/user-attachments/assets/8333aece-303a-46c4-bd90-42be6b673228)

时间片轮转：
将所有就绪进程按 先来先服务的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。
时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。
![image](https://github.com/user-attachments/assets/fb835c37-e20a-42fd-a27b-d4ae32dcd5aa)

最短剩余时间优先：
最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

### 进程间通信有哪些方式？
![image](https://github.com/user-attachments/assets/01722788-4f08-4915-80fc-d4613653bec4)

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

![image](https://github.com/user-attachments/assets/a6777067-1cfc-4c21-ab5b-65afeaacccb7)

#### 管道
如果你学过 Linux 命令，那你肯定很熟悉「|」这个竖线。

$ ps auxf | grep mysql

上面命令行里的「|」竖线就是一个管道，它的功能是将前一个命令（ps auxf）的输出，作为后一个命令（grep mysql）的输入，从这功能描述，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。

同时，我们得知上面这种管道是没有名字，所以「|」表示的管道称为匿名管道，用完了就销毁。

管道还有另外一个类型是命名管道，也被叫做 FIFO，因为数据是先进先出的传输方式。

在使用命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：

$ mkfifo myPipe

myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：

接下来，我们往 myPipe 这个管道写入数据：

$ echo "hello" > myPipe  // 将数据写进管道

你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。于是，我们执行另外一个命令来读取这个管道里的数据：

$ cat < myPipe  // 读取管道里的数据

所谓的管道，就是内核里面的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。

另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。A 和 B 之间不存在父子关系，它俩的父进程都是 shell。

所以说，在 shell 里通过「|」匿名管道将多个命令连接在一起，实际上也就是创建了多个子进程，那么在我们编写 shell 脚本时，能使用一个管道搞定的事情，就不要多用一个管道，这样可以减少创建子进程的系统开销。

我们可以得知，对于匿名管道，它的通信范围是存在父子关系的进程。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。

另外，对于命名管道，它可以在不相关的进程间也能相互通信。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。

不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。

#### 消息队列
前面说到管道的通信方式是效率低的,因此管道不适合进程间频繁地交换数据

对于这个问题,消息队列的通信模式就可以解决。比如,A进程要给B进程发送消息,A进程把数据放在对应的消息队列后就可以正常返回了,B进程需要的时候再去读取数据就可以了。同理,B进程要给A进程发送消息也是如此。

再来,消息队列是保存在内核中的消息链表,在发送数据时,会分成一个一个独立的数据单元,也就是消息体(数据块),消息体是用户自定义的数据类型,消息的发送方和接收方要约定好消息体的数据类型,所以每个消息体都是固定大小的存储块,不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体,内核就会把这个消息体删除。

消息队列生命周期随内核,如果没有释放消息队列或者没有关闭操作系统,消息队列会一直存在,而前面提到的匿名管道的生命周期,是随进程的创建而建立,随进程的结束而销毁。

消息这种模型,两个进程之间的通信就像平时发邮件一样,你来一封,我回一封,可以频繁沟通了。但邮件的通信方式存在不足的地方有两点,一是通信不及时,二是附件也有大小限制,这同样也是消息队列通信不足的点。

消息队列不适合比较大数据的传输,因为在内核中每个消息体都有一个最大长度的限制,同时所有队列所包含的全部消息体的总长度也是有上限。在Linux内核中,会有两个宏定义 MSGMAX和MSGMNB,它们以字节为单位,分别定义了一条消息的最大长度和一个队列的最大长度。

消息队列通信过程中,存在用户态与内核态之间的数据拷贝开销,因为进程写入数据到内核中的消息队列时,会发生从用户态拷贝数据到内核态的过程,同理另一进程读取内核中的消息数据时,会发生从内核态拷贝数据到用户态的过程。

#### 共享内存

消息队列的读取和写入的过程,都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式,就很好的解决了这一问题。

现代操作系统,对于内存管理,采用的是虚拟内存技术,也就是每个进程都有自己独立的虚拟内存空间,不同进程的虚拟内存映射到不同的物理内存中。所以,即使进程A和进程B的虚拟地址是一样的,其实访问的是不同的物理内存地址,对于数据的增删查改互不影响。

共享内存的机制,就是拿出一块虚拟地址空间来,映射到相同的物理内存中。这样这个进程写入的东西,另外一个进程马上就能看到了,都不需要拷贝来拷贝去,传来传去,大大提高了进程间通信的速度。


![image](https://github.com/user-attachments/assets/6e621a94-366a-4f28-ab4e-5cc9f62d8484)

#### 信号量

用了共享内存通信方式,带来新的问题,那就是如果多个进程同时修改同一个共享内存,很有可能就冲突了。例如两个进程都同时写一个地址,那先写的那个进程会发现内容被别人覆盖了。

为了防止多进程竞争共享资源,而造成的数据错乱,所以需要保护机制,使得共享的资源,在任意时刻只能被一个进程访问。正好,信号量就实现了这一保护机制。

信号量其实是一个整型的计数器,主要用于实现进程间的互斥与同步,而不是用于缓存进程间通信的数据。信号量表示资源的数量,控制信号量的方式有两种原子操作:

一个是P操作,这个操作会把信号量减去1,相减后如果信号量<0,则表明资源已被占用,进程需阻塞等待;相减后如果信号量>=0,则表明还有资源可使用,进程可正常继续执行。

另一个是V操作,这个操作会把信号量加上1,相加后如果信号量<=0,则表明当前有阻塞中的进程,于是会将该进程唤醒运行;相加后如果信号量>0,则表明当前没有阻塞中的进程;

P操作是用在进入共享资源之前,V操作是用在离开共享资源之后,这两个操作是必须成对出现的。

接下来,举个例子,如果要使得两个进程互斥访问共享内存,我们可以初始化信号量为 1。

![image](https://github.com/user-attachments/assets/62715b2a-5d50-4279-826a-ba352cdcf4ef)

具体的过程如下:

进程A在访问共享内存前,先执行了P操作,由于信号量的初始值为1,故在进程A执行P操作后信号量变为0,表示共享资源可用,于是进程A就可以访问共享内存。
若此时,进程B也想访问共享内存,执行了P操作,结果信号量变为了-1,这就意味着临界资源已被占用,因此进程B被阻塞。

直到进程A访问完共享内存,才会执行V操作,使得信号量恢复为0,接着就会唤醒阻塞中的线程B,使得进程B可以访问共享内存,最后完成共享内存的访问后,执行V操作,使信号量恢复到初始值1。

可以发现,信号初始化为1,就代表着是互斥信号量,它可以保证共享内存在任何时刻只有一个进程在访问,这就很好的保护了共享内存。另外,在多进程里,每个进程并不一定是顺序执行的,它们基本是以各自独立的、不可预知的速度向前推
进,但有时候我们又希望多个进程能密切合作,以实现一个共同的任务。

例如,进程A是负责生产数据,而进程B是负责读取数据,这两个进程是相互合作、相互依赖的,进程A必须先生产了数据,进程B才能读取到数据,所以执行是有前后顺序的。

那么这时候,就可以用信号量来实现多进程同步的方式,我们可以初始化信号量为0。


![image](https://github.com/user-attachments/assets/e55fa972-0b3b-4d85-ac51-2c1f0689d9a3)

具体过程:

如果进程B比进程A先执行了,那么执行到P操作时,由于信号量初始值为0,故信号量会变为-1,表示进程A还没生产数据,于是进程B就阻塞等待;

接着,当进程A生产完数据后,执行了V操作,就会使得信号量变为0,于是就会唤醒阻塞在P操作的进程B;

最后,进程B被唤醒后,意味着进程A已经生产了数据,于是进程B就可以正常读取数据了。可以发现,信号初始化为0,就代表着是同步信号量,它可以保证进程A应在进程B之前执行。

#### 信号

上面说的进程间通信,都是常规状态下的工作模式。对于异常情况况下的工作模式,就需要用「信号」的方式来通知进程。

在Linux操作系统中,为了响应各种各样的事件,提供了几十种信号,分别代表不同的意义。我们可以通过kill-l命令,查看所有的信号。

运行在shell终端的进程,我们可以通过键盘输入某些组合键的时候,给进程发送信号。例如

Ctrl+C产生SIGINT信号,表示终止该进程;

Ctrl+Z产生SIGTSTP信号,表示停止该进程,但还未结束;

如果进程在后台运行,可以通过 kill命令的方式给进程发送信号,但前提需要知道运行中的进程PID号,例如: kill -9 1050,表示给PID为1050的进程发送SIGKILL信号,用来立即结束该进程;
所以,信号事件的来源主要有硬件来源(如键盘Cltr+C)和软件来源(如kill命令)。信号是异步通信机制,因为可以在任何时候发送信号给某一进科程,一旦有信号产生,我们就有下面这几种,用户进程对信号的处理方式。

1.执行默认操作。Linux对每种信号都规定了默认操作,例如,上面列表中的SIGTERM信号,就是终止进程的意思。

2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发发生时,我们就执行相应的信号处理函数。

3.忽略信号。当我们不希望处理某些信号的时候,就可以忽略该该信号,不做任何处理。有两个信号是应用进程无法捕捉和忽略的,即SIGKILL 和 SEGSTOP,它们用于在任何时候中断或结束某一进程。

#### Socket

前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信,那要想跨网络与不同主机上的进程之间通信,就需要Socket通信了。

实际上,Socket通信不仅可以跨网络与不同主机的进程间通信,还还可以在同主机上进程间通信。

我们来看看创建socket的系统调用:

> int socket(int domain, int type,int protocal)

三个参数分别代表:

domain参数用来指定协议族,比如AF_INET用于IPV4、AF_INET6用于IPV6、AF_LOCAL/AF_UNIX用于本机;

type参数用来指定通信特性,比如SOCK_STREAM表示的是字节流,对应TCP、SOCK_DGRAM表示的是数据报,对应UDP、SOCK_RAW表示的是原始套接字;

protocal参数原本是用来指定通信协议的,但现在基本废弃。因为协议已经通过前面两个参数指定完成,protocol目前一般写成0即可;

根据创建socket类型的不同,通信的方式也就不同:

实现TCP字节流通信:socket类型是AF_INET和SOCK_STREAM

实现UDP数据报通信:socket类型是AF_INET和SOCK_DGRAM;

实现本地进程间通信:「本地字节流socket」类型是AF_LOCAL和SOCK_STREAM,「本地数据报socket」类型是AF_LOCAL和SOCK_DGRAM。另外,AF_UNIX和AF_LOCAL是等价的,所以AF_UNIX也属于本地socket;

接下来,简单说一下这三种通信的编程模式。

> 针对 TCP 协议通信的 socket 编程模型

![image](https://github.com/user-attachments/assets/8da6253d-d810-4b85-aeab-15660e8af434)

服务端和客户端初始化socket,得到文件描述符;

服务端调用bind,将绑定在IP地址和端口;

服务端调用listen,进行监听;

服务端调用accept,等待客户端连接;

客户端调用connect,向服务器端的地址和端口发起连接请求;

服务端 accept返回用于传输的socket的文件描述符;

客户端调用write写入数据;服务端调用read读取数据;

客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。

这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以,监听的socket和真正用来传送数据的socket,是「两个」socket,一个叫作监听socket,一个叫作已完成连接socket。

成功连接建立之后,双方开始通过read和write函数来读写数据,就就像往一个文件流里面写东西一样

> 针对 UDP 协议通信的 socket 编程模型

![image](https://github.com/user-attachments/assets/83afe758-f8a6-4f66-b7c8-3de1b1794284)

UDP是没有连接的,所以不需要三次握手,也就不需要像TCIP调用listen和connect,但是UDP的交互仍然需要IP地址和端口号,因此也需要bind。

对于UDP来说,不需要要维护连接,那么也就没有所谓的发送方和接收方,甚至都不存在客户端和服务端的概念,只要有一个socket多台机器就可以任意通信,因此比每一个UDP的socket都需要bind。

另外,每次通信时,调用sendto和recvfrom,都要传入目标主机的IP地址和端口。

> 针对本地进程间通信的socket编程模型

本地socket被用于在同一台主机上进程间通信的场景:

本地socket的编程接口和IPV4、IPv6套接字编程接口是一到故的,可以支持「字节流」和「数据报」两种协议;

本地socket的实现效率大大高于IPv4和IPv6的字节流、数据报sodcket实现;

对于本地字节流socket,其socket类型是AF_LOCAL和SOCK_STREAM

对于本地数据报socket,其socket类型是AF_LOCAL 和SOCK_DGRAM.

本地字节流socket和本地数据报 socket在bind的时候,不像TCP和UDP要绑定IP地址和端口,而是**绑定一个本地文件**,这也就是它们之间的最大区别。

#### 总结

由于每个进程的用户空间都是独立的,不能相互访问,这时就需要借助内核空间来实现进程间通信,原因很简单,**每个进程都是共享一个内核空间**。

Linux内核提供了不少进程间通信的方式,其中最简单的方式就是管道,管道分为「匿名管道」和「命名管道」。匿名管道顾名思义,它没有名字标识,匿名管道是特殊文件只存在于内存,没有存在于文件系统中,shell
命令中的「|」竖线就是匿名管道,通信的数据是无格式的流并且大小受限,通信的方式是单向的,数据只能在一个方向上流动,如果要双向通信,需要创建两个管道再来匿名管道是只能用于存在父子关系
的进程间通信,匿名管道的生命周期随着进程创建而建立,随着进程线终止而消失命名管道突破了匿名管道只能在亲缘关系进程间的通信限制,因为使用命名管道的前提,需要在文件系统
创建一个类型为p的设备文件,那么毫无关系的进程就可以通过这个设备文件进行通信。另外,不管是匿名管道还是命名管道,进程写入的数据都是缓存在内核中,另一个进程读取数据时候自然也是从内核中获
取,同时通信数据都遵循先进先出原则,不支持Iseek之类的文件定位操作。

消息队列克服了管道通信的数据是无格式的字节流的问题,消息队列实际上是保存在内核的「消息链表」,消息队列的消息体是可以用户自定义的数据类型,发送数居时,会被分成一个一个独立的消息体,当然接收数据时,也要与发送方发送的消息体的数据类型保持一致,这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的,毕竟每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。


共享内存可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销,它直接分配一个共享空间,每个进程都可以直接访问,就像访问进程自己的空间一样快捷方便,不需要陷入内核态或者系统调
用,大大提高了通信的速度,享有最快的进程间通信方式之名。但是便捷高效的共享内存通信,带来新的问题,多进程竞争同个共享资源会造成数据的错乱。

那么,就需要信号量来保护共享资源,以确保任何时刻只能有一个进程访问共享资源,这种方式就是互斥访问。信号量不仅可以实现访问的互斥性,还可以实现进程间的同步,信号量其实是一个计数器,表示的
是资源个数,其值可以通过两个原子操作来控制,分别是P操作和V操作。

与信号量名字很相似的叫信号,它俩名字虽然相似,但功能一点儿都不下一样。信号是异步通信机制,信号可以在应用进程和内核之间直接交互,内核也可以利用信号来通知用户空间的进程发生了哪些系统事件,
信号事件的来源主要有硬件来源(如键盘Cltr+C)和软件来源(如kiill命令),一旦有信号发生,进程有三种方式响应信号1.执行默认操作、2.捕捉信号、3.忽略信号号。有两个信号是应用进程无法捕捉和忽略
的,即SIGKILL 和SIGSTOP,这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制,都是工作于同一台主机,如果要与不同主机的进程间通信,那么就需要Socket通信了。Socket实际上不仅用于不同的主机进程间通信,还可以用于本地主机进程间通信,可根据创建
Socket的类型不同,分为三种常见的通信方式,一个是基于TCP协议义的通信方式,一个是基于UDP协议的通信方式,一个是本地进程间通信方式。

以上,就是进程间通信的主要机制了。你可能会问了,那线程通信间的为方式呢?

同个进程下的线程之间都是共享进程的资源,只要是共享变量都可以做做到线程间通信,比如全局变量,所以对于线程间关注的不是通信方式,而是关注多线程竞争共享资源的问题,信号量也同样可以在线程间实
现互斥与同步:

互斥的方式,可保证任意时刻只有一个线程访问共享资源;

同步的方式,可保证线程A应在线程B之前执行;

### 进程和线程的联系和区别？

线程和进程的联系：

线程是进程当中的⼀条执⾏流程。

同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的。

![image](https://github.com/user-attachments/assets/fcd32967-1559-4853-ba83-2b51f1d02cf1)

线程与进程的⽐较如下：

调度：进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；

资源：进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；

拥有资源：线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；

系统开销：线程能减少并发执⾏的时间和空间开销——创建或撤销进程时，系统都要为之分配或回收系统资源，如内存空间，I/O设备等，OS所付出的开销显著大于在创建或撤销线程时的开销，进程切换的开销也远大于线程切换的开销。

### 线程上下文切换了解吗？

这还得看线程是不是属于同⼀个进程：

当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；

当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；

所以，线程的上下⽂切换相⽐进程，开销要⼩很多。

### 线程有哪些实现方式？

主要有三种线程的实现⽅式：

**内核态线程实现**：在内核空间实现的线程，由内核直接管理线程。

![image](https://github.com/user-attachments/assets/e7d1b95b-b108-4eb1-93b8-5a4ece052360)

**⽤户态线程实现**：在⽤户空间实现线程，不需要内核的参与，内核对线程无感知。

![image](https://github.com/user-attachments/assets/429b29eb-eadf-45b5-aa65-5c6d314d2990)

**混合线程实现**：现代操作系统基本都是将两种方式结合起来使用。用户态的执行系统负责进程内部线程在非阻塞时的切换；内核态的操作系统负责阻塞线程的切换。即我们同时实现内核态和用户态线程管理。其中内核态线程数量较少，而用户态线程数量较多。每个内核态线程可以服务一个或多个用户态线程。

![image](https://github.com/user-attachments/assets/e9af399f-da0a-4de7-9468-fa93d29ef071)

### 线程间如何同步？

同步解决的多线程操作共享资源的问题，目的是不管线程之间的执行如何穿插，最后的结果都是正确的。

我们前面知道线程和进程的关系：线程是进程当中的⼀条执⾏流程。所以说下面的一些同步机制不止针对线程，同样也可以针对进程。

临界区：我们把对共享资源访问的程序片段称为临界区，我们希望这段代码是互斥的，保证在某时刻只能被一个线程执行，也就是说一个线程在临界区执行时，其它线程应该被阻止进入临界区。

![image](https://github.com/user-attachments/assets/1f398768-dc78-45ee-a131-7bc505fd70f6)

临界区不仅针对线程，同样针对进程。

临界区同步的一些实现方式：

**1、锁**

使⽤加锁操作和解锁操作可以解决并发线程/进程的互斥问题。

任何想进⼊临界区的线程，必须先执⾏加锁操作。若加锁操作顺利通过，则线程可进⼊临界区；在完成对临界资源的访问后再执⾏解锁操作，以释放该临界资源。

加锁和解锁锁住的是什么呢？可以是临界区对象，也可以只是一个简单的互斥量，例如互斥量是0无锁，1表示加锁。

![image](https://github.com/user-attachments/assets/090565e9-ebec-4d2a-aed2-142b7671415e)

根据锁的实现不同，可以分为忙等待锁和和⽆忙等待锁。

忙等待锁和就是加锁失败的线程，会不断尝试获取锁，也被称为自旋锁，它会一直占用CPU。

⽆忙等待锁就是加锁失败的线程，会进入阻塞状态，放弃CPU，等待被调度。

**2、信号量**

信号量是操作系统提供的⼀种协调共享资源访问的⽅法。

通常信号量表示资源的数量，对应的变量是⼀个整型（ sem ）变量。

另外，还有两个原⼦操作的系统调⽤函数来控制信号量的，分别是：

P 操作：将 sem 减 1 ，相减后，如果 sem < 0 ，则进程/线程进⼊阻塞等待，否则继续，表明 P操作可能会阻塞；

V 操作：将 sem 加 1 ，相加后，如果 sem <= 0 ，唤醒⼀个等待中的进程/线程，表明 V 操作不会阻塞；

P 操作是⽤在进⼊临界区之前，V 操作是⽤在离开临界区之后，这两个操作是必须成对出现的。

### 什么是死锁？

在两个或者多个并发线程中，如果每个线程持有某种资源，而又等待其它线程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组线程产生了死锁。通俗的讲就是两个或多个线程无限期的阻塞、相互等待的一种状态。

![image](https://github.com/user-attachments/assets/aaeaefd9-37b5-4fbd-b893-8028fa76bd19)

### 死锁产生有哪些条件？

死锁产生需要同时满足四个条件：

互斥条件：指线程对己经获取到的资源进行它性使用，即该资源同时只由一个线程占用。如果此时还有其它线程请求获取获取该资源，则请求者只能等待，直至占有资源的线程释放该资源。

请求并持有条件：指一个 线程己经持有了至少一个资源，但又提出了新的资源请求，而新资源己被其它线程占有，所以当前线程会被阻塞，但阻塞 的同时并不释放自己已经获取的资源。

不可剥夺条件：指线程获取到的资源在自己使用完之前不能被其它线程抢占，只有在自己使用完毕后才由自己释放该资源。

环路等待条件：指在发生死锁时，必然存在一个线程——资源的环形链，即线程集合 {T0，T1，T2,…… ，Tn} 中 T0 正在等待一 T1 占用的资源，Tl1正在等待 T2用的资源，…… Tn 在等待己被 T0占用的资源。

### 如何避免死锁呢？

产⽣死锁的有四个必要条件：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。

避免死锁，破坏其中的一个就可以。

消除互斥条件

这个是没法实现，因为很多资源就是只能被一个线程占用，例如锁。

消除请求并持有条件

消除这个条件的办法很简单，就是一个线程一次请求其所需要的所有资源。

消除不可剥夺条件

占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可剥夺这个条件就破坏掉了。

消除环路等待条件

可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后就不存在环路了。

### 活锁和饥饿锁了解吗？

饥饿锁：

饥饿锁，这个饥饿指的是资源饥饿，某个线程一直等不到它所需要的资源，从而无法向前推进，就像一个人因为饥饿无法成长。

活锁：

在活锁状态下，处于活锁线程组里的线程状态可以改变，但是整个活锁组的线程无法推进。

活锁可以用两个人过一条很窄的小桥来比喻：为了让对方先过，两个人都往旁边让，但两个人总是让到同一边。这样，虽然两个人的状态一直在变化，但却都无法往前推进。

线程虽然在运行，但总是处于 尝试获取资源 → 失败 → 让步 → 再尝试 的状态，导致程序无法前进，就像两个客人不断互相让路，谁都不先走。

两个线程检测到资源被占后都主动释放，然后重新尝试获取，彼此一直让步，但从不真正执行核心逻辑。

### 内存管理

#### 什么是虚拟内存？

我们实际的物理内存主要是主存，但是物理主存空间有限，所以一般现代操作系统都会想办法把一部分内存块放到磁盘中，用到的时候再装入主存，但是对用户程序而言，是不需要注意实际的物理内存的，为什么呢？因为有虚拟内存的机制。

简单说，虚拟内存是操作系统提供的⼀种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。

每个进程都有自己独立的地址空间，再由操作系统映射到到实际的物理内存。

于是，这⾥就引出了两种地址的概念：

程序所使⽤的内存地址叫做虚拟内存地址（Virtual Memory Address）

实际存在硬件⾥⾯的空间地址叫物理内存地址（Physical Memory Address）。

![image](https://github.com/user-attachments/assets/0ec80880-4f6b-413f-a583-0893d1118b33)

#### 什么是内存分段？

程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。

分段机制下的虚拟地址由两部分组成，段号和段内偏移量。

虚拟地址和物理地址通过段表映射，段表主要包括段号、段的界限。

![image](https://github.com/user-attachments/assets/873da5de-6a05-4629-a84e-e39b630ebc2c)

我们来看一个映射，虚拟地址：段3、段偏移量500  ---->  段基地址7000+段偏移量500 ----> 物理地址：7500。

![image](https://github.com/user-attachments/assets/06281b6d-ace2-4426-b688-299274b0c2ea)

#### 什么是内存分页？

访问分页系统中内存数据需要两次的内存访问 ：一次是从内存中访问页表，从中找到指定的物理页号，加上页内偏移得到实际物理地址，第二次就是根据第一次得到的物理地址访问内存取出数据。

![image](https://github.com/user-attachments/assets/79ce49c0-c65d-4192-b352-dbf7970184a5)

#### 多级页表知道吗？

操作系统可能会有非常多进程，如果只是使用简单分页，可能导致的后果就是页表变得非常庞大。

所以，引入了多级页表的解决方案。

所谓的多级页表，就是把我们原来的单级页表再次分页，这里利用了局部性原理，除了顶级页表，其它级别的页表一来可以在需要的时候才被创建，二来内存紧张的时候还可以被置换到磁盘中。

![image](https://github.com/user-attachments/assets/5f482946-498e-4a47-a5cc-116b35d5e461)

#### 什么是局部性原理

局部性原理（Principle of Locality）是计算机系统中程序访问存储器（内存）时呈现出的一种规律性，它是现代计算机内存体系设计（如缓存、虚拟内存）的理论基础。

局部性原理分为两个主要类型：

1. 时间局部性（Temporal Locality）

意思：如果某个数据被访问过，那么它很可能在不久的将来会再次被访问。
应用：缓存机制：把最近访问的数据保留在高速缓存（CPU Cache）中，提高命中率。

2. 空间局部性（Spatial Locality）

意思：如果某个内存地址被访问了，那么它附近的地址很可能也会很快被访问。
应用：预取机制：操作系统和硬件会提前加载相邻数据块，提高内存访问效率。

#### 什么是块表？

同样利用了局部性原理，即在⼀段时间内，整个程序的执⾏仅限于程序中的某⼀部分。相应地，执⾏所访问的存储空间也局限于某个内存区域。

利⽤这⼀特性，把最常访问的⼏个⻚表项存储到访问速度更快的硬件，于是计算机科学家们，就在 CPU 芯⽚中，加⼊了⼀个专⻔存放程序最常访问的⻚表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为⻚表缓存、转址旁路缓存、快表等。

![image](https://github.com/user-attachments/assets/44ef2852-c649-4849-905f-1c6d9f1c440b)

#### 分页和分段有什么区别？

段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。

段的大小不固定，有它所完成的功能决定；页的大小固定，由系统决定

段向用户提供二维地址空间；页向用户提供的是一维地址空间

段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。

#### 什么是交换空间？

操作系统把物理内存(Physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时，Linux把某些页的内容转移至磁盘上的一块空间上，以释放内存空间。磁盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。

用途：
物理内存不足时一些不常用的页可以被交换出去，腾给系统。
程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。

#### 页面置换算法有哪些？

在分页系统里，一个虚拟的页面可能在主存里，也可能在磁盘中，如果CPU发现虚拟地址对应的物理页不在主存里，就会产生一个缺页中断，然后从磁盘中把该页调入主存中。

如果内存里没有空间，就需要从主存里选择一个页面来置换。

常见的页面置换算法：

![image](https://github.com/user-attachments/assets/7f981b1c-3a78-43c0-8bc8-92ff8ebe9a98)

1. 最佳⻚⾯置换算法（OPT）

最佳⻚⾯置换算法是一个理想的算法，基本思路是，置换在未来最⻓时间不访问的⻚⾯。

所以，该算法实现需要计算内存中每个逻辑⻚⾯的下⼀次访问时间，然后⽐较，选择未来最⻓时间不访问的⻚⾯。

但这个算法是无法实现的，因为当缺页中断发生时，操作系统无法知道各个页面下一次将在什么时候被访问。

2. 先进先出置换算法（FIFO）

既然我们⽆法预知⻚⾯在下⼀次访问前所需的等待时间，那可以选择在内存驻留时间很⻓的⻚⾯进⾏中置换，这个就是「先进先出置换」算法的思想。

FIFO的实现机制是使用链表将所有在内存的页面按照进入时间的早晚链接起来，然后每次置换链表头上的页面就行了，新加进来的页面则挂在链表的末端。

![image](https://github.com/user-attachments/assets/f342231b-6b27-4d18-82d7-2bf1b482327d)

3. 最近最久未使⽤的置换算法（LRU）
   
最近最久未使⽤（LRU）的置换算法的基本思路是，发⽣缺⻚时，选择最⻓时间没有被访问的⻚⾯进⾏置换，也就是说，该算法假设已经很久没有使⽤的⻚⾯很有可能在未来较⻓的⼀段时间内仍然不会被使⽤。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使⽤情况来推测要淘汰的⻚⾯，⽽ LRU 则是通过历史的使⽤情况来推测要淘汰的⻚⾯。

LRU 在理论上是可以实现的，但代价很⾼。为了完全实现 LRU，需要在内存中维护⼀个所有⻚⾯的链表，最近最多使⽤的⻚⾯在表头，最近最少使⽤的⻚⾯在表尾。

![image](https://github.com/user-attachments/assets/b4e4b96b-1ccc-46d0-ab25-a05c110fe5c2)

困难的是，在每次访问内存时都必须要更新整个链表。在链表中找到⼀个⻚⾯，删除它，然后把它移动到表头是⼀个⾮常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销⽐较⼤，实际应⽤中⽐较少使⽤。

4. 时钟页面置换算法

这个算法的思路是，把所有的⻚⾯都保存在⼀个类似钟⾯的环形链表中，⼀个表针指向最⽼的⻚⾯。

它用一个指针模拟时钟的分针，顺时针扫描页面表，寻找被淘汰的页面。每个页面有一个访问位（访问标志位，access bit 或 use bit）。

假设每个页框（page frame）都有一个访问位 A，初始都为 0。

    当一个页面被访问（读/写）时 → 设置其 A = 1；

    页面置换时：

        查看当前指针指向页的 A；

        如果 A = 0，说明近期未被访问，选择该页淘汰；

        如果 A = 1，说明刚刚访问过，将其 A = 0，然后移动指针到下一页，继续查找；

    不断循环，直到找到 A = 0 的页进行替换。
    
5. 最不常⽤置换算法
   
最不常用算法（LFU），当发⽣缺⻚中断时，选择访问次数最少的那个⻚⾯，将其置换。

它的实现⽅式是，对每个⻚⾯设置⼀个「访问计数器」，每当⼀个⻚⾯被访问时，该⻚⾯的访问计数器就累加 1。在发⽣缺⻚中断时，淘汰计数器值最⼩的那个⻚⾯。

### 文件

#### 硬链接和软链接有什么区别？

硬链接就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode。删除任意一个条目，文件还是存在，只要引用数量不为 0。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。

![image](https://github.com/user-attachments/assets/049ac369-131c-4665-b8b6-7146e20880ed)

软链接相当于重新创建⼀个⽂件，这个⽂件有独⽴的 inode，但是这个⽂件的内容是另外⼀个⽂件的路径，所以访问软链接的时候，实际上相当于访问到了另外⼀个⽂件，所以软链接是可以跨⽂件系统的，甚⾄⽬标⽂件被删除了，链接⽂件还是在的，只不过打不开指向的文件了而已。

![image](https://github.com/user-attachments/assets/a2f95943-77ab-4ec5-a80d-567dc1a37795)



